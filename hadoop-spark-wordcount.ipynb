{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d6c00-c5e1-4f02-9a75-9c7dab252a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc8d99-7498-47a4-9999-c1792c47c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745ac55-506d-49bb-adbc-d33009b05135",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WordCount\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8970cc9-a3bf-4a35-871c-602a5d5ae4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce89089-d7b7-4cb1-b64a-3feac4019938",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/home/adithan/hadoop/data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cf19f-3451-4156-b753-58b3d1e4bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119a71f-62e6-463e-89c6-7c9dda3a45f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f6e48-d9df-4ef2-983f-44ba2005ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = spark.sparkContext.textFile(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4204356-eebf-4cc4-84b5-38b13109fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = text_rdd.flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b7fce0-30bd-4269-afb5-23a44b794205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# Initialize Spark\n",
    "conf = SparkConf().setAppName(\"WordCount\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"/home/adithan/hadoop/data.txt\"  # Change this if your path is different\n",
    "\n",
    "# Read the text file into an RDD\n",
    "text_rdd = sc.textFile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc6c01-d41b-46c7-8d01-a87dc979022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = sc.textFile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ebb6c-194d-4eeb-888a-5ee906edc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4a90f-fe60-4a06-adfb-811b5bd89e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = text_rdd.flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f522fdb9-f60a-4a78-9a44-82d8eefc4d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/26 14:45:54 WARN Utils: Your hostname, ADITHAN-MSI-M14B11SBU resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/10/26 14:45:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/26 14:45:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WordCount\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320aa50e-f9b8-4488-90e3-92ae31d56c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = spark.sparkContext.textFile(\"hdfs://localhost:9000/user/adithan/data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3cba18-7dc5-42af-941c-01ed2f00e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = (text_rdd.flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1feae76-4dcd-452a-b070-8f6e1823d49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDFS: 1\n",
      "is: 2\n",
      "storage: 1\n",
      "both: 1\n",
      "of: 1\n",
      "are: 1\n",
      "really: 1\n",
      "cool.: 1\n",
      "a: 2\n",
      "unit: 2\n",
      "and: 1\n",
      "mapreduce: 1\n",
      "function: 1\n",
      "which: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results = word_counts.collect()\n",
    "for word, count in results:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb502b0-3e2c-4a60-a1a8-2c4e3dad084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eee853-526b-4936-a95d-d257c89696c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
